----------------------------------------
科目：machine_learning
0. 问题：陈述 1| 线性回归估计量在所有无偏估计量中方差最小。陈述 2| 分配给 AdaBoost 组装的分类器的系数 α 始终为非负值。 (machine_learning)
A. 正确，正确
B. 错误，错误
C. 正确，错误
D. 错误，正确
----------------------------------------------------------------

----------------------------------------------------------------
科目：machine_learning
1. 问题：陈述 1| RoBERTa 在比 BERT 预训练的语料库大 10 倍左右的语料库上进行预训练。陈述 2| 2018 年的 ResNeXts 通常使用 tanh 激活函数。 (machine_learning)
A. 正确，正确
B. 错误，错误
C. 正确，错误
D. 错误，正确
----------------------------------------------------------------

----------------------------------------------------------------
科目：machine_learning
2. 问题：陈述 1| 支持向量机（如逻辑回归模型）根据输入示例给出可能标签的概率分布。陈述 2| 当我们从线性核转移到高阶多项式核时，我们期望支持向量总体上保持不变。 (machine_learning)
A. 正确，正确
B. 错误，错误
C. 正确，错误
D. 错误，正确
----------------------------------------------------------------

----------------------------------------------------------------
科目：machine_learning
3. 问题：机器学习问题涉及四个属性和一个类。每个属性都有 3、2、2 和 2 个可能值。类有 3 个可能值。最多有多少个可能的不同示例？ (machine_learning)
A. 12
B. 24
C. 48
D. 72
----------------------------------------------------------------

----------------------------------------------------------------
科目：machine_learning
4. 问题：截至 2020 年，哪种架构最适合对高分辨率图像进行分类？ (machine_learning)
A. 卷积网络
B. 图网络
C. 全连接网络
D. RBF 网络
----------------------------------------------------------------

----------------------------------------------------------------
科目：machine_learning
5. 问题：陈述 1| 数据的对数似然将始终通过期望最大化算法的连续迭代而增加。陈述 2| Q 学习的一个缺点是，只有当学习者事先知道其行为如何影响其环境时才能使用它。 (machine_learning)
A. 正确，正确
B. 错误，错误
C. 正确，错误
D. 错误，正确
----------------------------------------------------------------

----------------------------------------------------------------
科目：machine_learning
6. 问题：假设我们已经计算了成本函数的梯度并将其存储在向量 g 中。给定梯度，一次梯度下降更新的成本是多少？ (machine_learning)
A. O(D)
B. O(N)
C. O(ND)
D. O(ND^2)
----------------------------------------------------------------

----------------------------------------------------------------
科目：machine_learning
7. 问题：陈述 1| 对于连续随机变量 x 及其概率分布函数 p(x)，对于所有 x，0 ≤ p(x) ≤ 1。陈述 2| 决策树是通过最小化信息增益来学习的。 (machine_learning)
A. 正确，正确
B. 错误，错误
C. 正确，错误
D. 错误，正确
----------------------------------------------------------------

----------------------------------------------------------------
科目：machine_learning
8. 问题：考虑下面给出的贝叶斯网络。此贝叶斯网络 H -> U <- P <- W 需要多少个独立参数？ (machine_learning)
A. 2
B. 4
C. 8
D. 16
----------------------------------------------------------------

----------------------------------------------------------------
科目：machine_learning
9. 问题：随着训练示例的数量趋于无穷大，您在该数据上训练的模型将具有： (machine_learning)
A. 方差较低
B. 方差较高
C. 方差相同
D. 以上都不是
----------------------------------------------------------------

----------------------------------------------------------------
科目：machine_learning
10. 问题：陈述 1| 2D 平面中所有矩形的集合（包括非轴对齐矩形）可以粉碎一组 5 个点。陈述 2|当 k = 1 时，k-最近邻分类器的 VC 维数为无穷大。 (machine_learning)
A. 正确，正确
B. 错误，错误
C. 正确，错误
D. 错误，正确
----------------------------------------------------------------

----------------------------------------------------------------
科目：machine_learning
11. 问题：_ 表示既不能对训练数据进行建模，也不能推广到新数据。 (machine_learning)
A. 拟合度高
B. 过度拟合
C. 欠拟合
D. 以上皆是
----------------------------------------------------------------

----------------------------------------------------------------
科目：machine_learning
12. 问题：陈述 1| F1 分数对于类别不平衡程度较高的数据集尤其有用。陈述 2| ROC 曲线下面积是评估异常检测器的主要指标之一。 (machine_learning)
A. 正确，正确
B. 错误，错误
C. 正确，错误
D. 错误，正确
----------------------------------------------------------------

----------------------------------------------------------------
科目：machine_learning
13. 问题：陈述 1| 反向传播算法学习具有隐藏层的全局最优神经网络。陈述 2| 一条线的 VC 维数最多应为 2，因为我至少可以找到一种 3 个点无法被任何一条线打断的情况。 (machine_learning)
A. 正确，正确
B. 错误，错误
C. 正确，错误
D. 错误，正确
----------------------------------------------------------------

----------------------------------------------------------------
科目：machine_learning
14. 问题：高熵意味着分类中的分区是 (machine_learning)
A. 纯的
B. 不纯的
C. 有用的
D. 无用的
----------------------------------------------------------------

----------------------------------------------------------------
科目：machine_learning
15. 问题：陈述 1| 原始 ResNet 论文中使用的是层规范化，而不是批量规范化。陈述 2| DCGAN 使用自注意力来稳定训练。 (machine_learning)
A. 正确，正确
B. 错误，错误
C. 正确，错误
D. 错误，正确
----------------------------------------------------------------

----------------------------------------------------------------
科目：machine_learning
16. 问题：在为特定数据集构建线性回归模型时，您会观察到其中一个特征的系数具有相对较高的负值。这表明 (machine_learning)
A. 该特征对模型有很强的影响（应保留）
B. 该特征对模型没有很强的影响（应忽略）
C. 如果没有其他信息，无法评论该特征的重要性
D. 无法确定。
----------------------------------------------------------------

----------------------------------------------------------------
科目：machine_learning
17. 问题：对于神经网络，以下哪一个结构假设最能影响欠拟合（即高偏差模型）和过拟合（即高方差模型）之间的权衡： (machine_learning)
A. 隐藏节点的数量
B. 学习率
C. 权重的初始选择
D. 使用常数项单元输入
----------------------------------------------------------------

----------------------------------------------------------------
科目：machine_learning
18. 问题：对于多项式回归，以下哪一个结构假设最能影响欠拟合和过拟合之间的权衡： (machine_learning)
A. 多项式次数
B. 我们是通过矩阵求逆还是梯度下降来学习权重
C. 高斯噪声的假设方差
D. 使用常数项单元输入
----------------------------------------------------------------

----------------------------------------------------------------
科目：machine_learning
19. 问题：陈述 1| 截至 2020 年，一些模型在 CIFAR-10 上的准确率超过 98%。陈述 2| 原始 ResNet 未使用 Adam 优化器进行优化。 (machine_learning)
A. 正确，正确
B. 错误，错误
C. 正确，错误
D. 错误，正确
----------------------------------------------------------------

----------------------------------------------------------------
科目：machine_learning
20. 问题：K 均值算法： (machine_learning)
A. 要求特征空间的维度不大于样本数量
B. 当 K = 1 时具有最小的目标函数值
C. 最小化给定数量簇的类内方差
D. 当且仅当初始均值被选为部分样本本身时，收敛到全局最优值
----------------------------------------------------------------

----------------------------------------------------------------
科目：machine_learning
21. 问题：陈述 1| VGGNets 的卷积核的宽度和高度小于 AlexNet 的第一层核。陈述 2| 在批量标准化之前引入了依赖于数据的权重初始化程序。 (machine_learning)
A. 正确，正确
B. 错误，错误
C. 正确，错误
D. 错误，正确
----------------------------------------------------------------

----------------------------------------------------------------
科目：machine_learning
22. 问题：以下矩阵的秩是多少？A = [[1, 1, 1], [1, 1, 1], [1, 1, 1]] (machine_learning)
A. 0
B. 1
C. 2
D. 3
----------------------------------------------------------------

----------------------------------------------------------------
科目：machine_learning
23. 问题：陈述 1|密度估计（例如，使用核密度估计器）可用于执行分类。陈述 2| 逻辑回归和高斯朴素贝叶斯（具有身份类协方差）之间的对应关系意味着两个分类器的参数之间存在一一对应关系。 (machine_learning)
A. 正确，正确
B. 错误，错误
C. 正确，错误
D. 错误，正确
----------------------------------------------------------------

----------------------------------------------------------------
科目：machine_learning
24. 问题：假设我们想对空间数据（例如房屋的几何位置）进行聚类。我们希望生成许多不同大小和形状的聚类。以下哪种方法最合适？ (machine_learning)
A. 决策树
B. 基于密度的聚类
C. 基于模型的聚类
D. K 均值聚类
----------------------------------------------------------------

----------------------------------------------------------------
科目：machine_learning
25. 问题：陈述 1| 在 AdaBoost 中，错误分类示例的权重以相同的乘积因子增加。陈述 2| 在 AdaBoost 中，第 t 个弱分类器在权重为 D_t 的训练数据上的加权训练误差 e_t 趋向于随着 t 的函数而增加。 (machine_learning)
A. 正确，正确
B. 错误，错误
C. 正确，错误
D. 错误，正确
----------------------------------------------------------------

----------------------------------------------------------------
科目：machine_learning
26. 问题：MLE 估计通常不受欢迎，因为 (machine_learning)
A. 它们有偏差
B. 它们具有高方差
C. 它们不是一致的估计量
D. 以上都不是
----------------------------------------------------------------

----------------------------------------------------------------
科目：machine_learning
27. 问题：梯度下降的计算复杂度是， (machine_learning)
A. 在 D 中是线性的
B. 在 N 中是线性的
C. 在 D 中是多项式的
D. 取决于迭代次数
----------------------------------------------------------------

----------------------------------------------------------------
科目：machine_learning
28. 问题：对多个决策树的输出进行平均有助于 _。 (machine_learning)
A. 增加偏差
B. 减少偏差
C. 增加方差
D. 减少方差
----------------------------------------------------------------

----------------------------------------------------------------
科目：machine_learning
29. 问题：通过对已识别的特征子集应用线性回归获得的模型可能与在识别子集过程中结束时获得的模型不同 (machine_learning)
A. 最佳子集选择
B. 前向逐步选择
C. 前向阶段选择
D. 以上所有
----------------------------------------------------------------

----------------------------------------------------------------
科目：machine_learning
30. 问题：神经网络： (machine_learning)
A. 优化凸目标函数
B. 只能使用随机梯度下降进行训练
C. 可以使用不同激活函数的混合
D. 以上都不是
----------------------------------------------------------------

----------------------------------------------------------------
科目：machine_learning
31. 问题：假设疾病 D 的发病率约为每 100 人 5 例（即 P(D) = 0.05）。让布尔随机变量 D 表示患者“患有疾病 D”，让布尔随机变量 TP 代表“检测呈阳性”。众所周知，对疾病 D 的测试非常准确，因为当您患有疾病时检测呈阳性的概率为 0.99，而当您没有患病时检测呈阴性的概率为 0.97。检测结果为阳性的先验概率 P(TP) 是多少？ (machine_learning)
A. 0.0368
B. 0.473
C. 0.078
D. 以上都不是
----------------------------------------------------------------

----------------------------------------------------------------
科目：machine_learning
32. 问题：陈述 1| 通过径向基核函数映射到特征空间 Q 后，使用无加权欧几里得距离的 1-NN 可能能够获得比原始空间更好的分类性能（尽管我们不能保证这一点）。陈述 2| 感知器的 VC 维小于简单线性 SVM 的 VC 维。 (machine_learning)
A. 正确，正确
B. 错误，错误
C. 正确，错误
D. 错误，正确
----------------------------------------------------------------

----------------------------------------------------------------
科目：machine_learning
33. 问题：网格搜索的缺点是 (machine_learning)
A. 它不能应用于不可微函数。
B. 它不能应用于非连续函数。
C. 它很难实现。
D. 对于多元线性回归，它的运行速度相当慢。
----------------------------------------------------------------

----------------------------------------------------------------
科目：machine_learning
34. 问题：根据各种线索预测某个地区的降雨量是一个 ______ 问题。 (machine_learning)
A. 监督学习
B. 无监督学习
C. 聚类
D. 以上都不是
----------------------------------------------------------------

----------------------------------------------------------------
科目：machine_learning
35. 问题：以下哪句话关于回归的说法是错误的？ (machine_learning)
A. 它将输入与输出联系起来。
B. 它用于预测。
C. 它可用于解释。
D. 它发现因果关系
----------------------------------------------------------------

----------------------------------------------------------------
科目：machine_learning
36. 问题：以下哪一项是修剪决策树的主要原因？ (machine_learning)
A. 为了节省测试期间的计算时间
B. 为了节省存储决策树的空间
C. 为了使训练集误差更小
D. 为了避免过度拟合训练集
----------------------------------------------------------------

----------------------------------------------------------------
科目：machine_learning
37. 问题：陈述 1| 核密度估计器相当于在原始数据集中的每个点 Xi 处执行值为 Yi = 1/n 的核回归。陈述 2| 学习决策树的深度可以大于用于创建树的训练示例的数量。 (machine_learning)
A. 正确，正确
B. 错误，错误
C. 正确，错误
D. 错误，正确
----------------------------------------------------------------

----------------------------------------------------------------
科目：machine_learning
38. 问题：假设您的模型过度拟合。以下哪项不是尝试减少过度拟合的有效方法？ (machine_learning)
A. 增加训练数据量。
B. 改进用于最小化误差的优化算法。
C. 降低模型复杂性。
D. 减少训练数据中的噪音。
----------------------------------------------------------------

----------------------------------------------------------------
科目：machine_learning
39. 问题：陈述 1| softmax 函数通常用于多类逻辑回归。陈述 2|非均匀 softmax 分布的温度会影响其熵。 (machine_learning)
A. 正确，正确
B. 错误，错误
C. 正确，错误
D. 错误，正确
----------------------------------------------------------------

----------------------------------------------------------------
科目：machine_learning
40. 问题：以下哪项关于 SVM 是正确的？ (machine_learning)
A. 对于二维数据点，线性 SVM 学习的分离超平面将是一条直线。
B. 理论上，高斯核 SVM 无法模拟任何复杂的分离超平面。
C. 对于 SVM 中使用的每个核函数，都可以获得等效的闭式基础展开。
D. SVM 中的过度拟合不是支持向量数量的函数。
----------------------------------------------------------------

----------------------------------------------------------------
科目：machine_learning
41. 问题：以下哪项是给定贝叶斯网络 H -> U <- P <- W 描述的 H、U、P 和 W 的联合概率？[注意：作为条件概率的乘积] (machine_learning)
A. P(H, U, P, W) = P(H) * P(W) * P(P) * P(U)
B. P(H, U, P, W) = P(H) * P(W) * P(P | W) * P(W | H, P)
C. P(H, U, P, W) = P(H) * P(W) * P(P | W) * P(U | H, P)
D. 以上都不是
----------------------------------------------------------------

----------------------------------------------------------------
科目：machine_learning
42. 问题：陈述 1| 由于具有径向基核的 SVM 的 VC 维数是无限的，因此这种 SVM 必须比具有有限 VC 维数的多项式核的 SVM 更差。陈述 2|具有线性激活函数的两层神经网络本质上是线性分离器的加权组合，在给定的数据集上进行训练；基于线性分离器构建的增强算​​法也会找到线性分离器的组合，因此这两种算法将给出相同的结果。 (machine_learning)
A. 正确，正确
B. 错误，错误
C. 正确，错误
D. 错误，正确
----------------------------------------------------------------

----------------------------------------------------------------
科目：machine_learning
43. 问题：陈述 1| ID3 算法保证找到最佳决策树。陈述 2| 考虑密度 f() 处处非零的连续概率分布。值 x 的概率等于 f(x)。 (machine_learning)
A. 正确，正确
B. 错误，错误
C. 正确，错误
D. 错误，正确
----------------------------------------------------------------

----------------------------------------------------------------
科目：machine_learning
44. 问题：给定一个具有 N 个输入节点、没有隐藏层、一个输出节点、具有熵损失和 S 型激活函数的神经网络，以下哪种算法（具有适当的超参数和初始化）可用于找到全局最优值？ (machine_learning)
A. 随机梯度下降
B. 小批量梯度下降
C. 批量梯度下降
D. 以上所有
----------------------------------------------------------------

----------------------------------------------------------------
科目：machine_learning
45. 问题：在线性模型中添加更多基函数将发生以下哪种情况，选择最可能的选项： (machine_learning)
A. 减少模型偏差
B. 减少估计偏差
C. 减少方差
D. 不影响偏差和方差
----------------------------------------------------------------

----------------------------------------------------------------
科目：machine_learning
46. 问题：考虑下面给出的贝叶斯网络。如果我们不对独立性或条件独立性 H -> U <- P <- W 做任何假设，我们需要多少个独立参数？ (machine_learning)
A. 3
B. 4
C. 7
D. 15
----------------------------------------------------------------

----------------------------------------------------------------
科目：machine_learning
47. 问题：“分布外检测”的另一个术语名称是什么？ (machine_learning)
A. 异常检测
B. 单类检测
C. 训练测试不匹配稳健性
D. 背景检测
----------------------------------------------------------------

----------------------------------------------------------------
科目：machine_learning
48. 问题：陈述 1| 我们通过提升弱学习者 h 来学习分类器 f。f 的决策边界的函数形式与 h 的相同，但参数不同。（例如，如果 h 是线性分类器，则 f 也是线性分类器）。陈述 2|交叉验证可用于选择提升中的迭代次数；此过程可能有助于减少过度拟合。 (machine_learning)
A. 正确，正确
B. 错误，错误
C. 正确，错误
D. 错误，正确
----------------------------------------------------------------

----------------------------------------------------------------
科目：machine_learning
49. 问题：陈述 1| Highway 网络是在 ResNets 之后引入的，它放弃了最大池化而采用卷积。 陈述 2| DenseNets 通常比 ResNets 占用更多内存。 (machine_learning)
A. 正确，正确
B. 错误，错误
C. 正确，错误
D. 错误，正确
----------------------------------------------------------------

----------------------------------------------------------------
科目：machine_learning
50. 问题：如果 N 是训练数据集中的实例数，则最近邻的分类运行时间为 (machine_learning)
A. O(1)
B. O( N )
C. O(log N )
D. O( N^2 )
----------------------------------------------------------------

----------------------------------------------------------------
科目：machine_learning
51. 问题：陈述 1| 原始 ResNets 和 Transformers 是前馈神经网络。陈述 2| 原始 Transformers 使用自注意力，但原始 ResNet 不使用。 (machine_learning)
A. 正确，正确
B. 错误，错误
C. 正确，错误
D. 错误，正确
----------------------------------------------------------------

----------------------------------------------------------------
科目：machine_learning
52. 问题：陈述 1| RELU 不是单调的，但 S 型函数是单调的。陈述 2| 用梯度下降训练的神经网络以高概率收敛到全局最优值。 (machine_learning)
A. 正确，正确
B. 错误，错误
C. 正确，错误
D. 错误，正确
----------------------------------------------------------------

----------------------------------------------------------------
科目：machine_learning
53. 问题：神经网络中 S 型函数节点的数值输出： (machine_learning)
A. 无界，包含所有实数。
B. 无界，包含所有整数。
C. 介于 0 和 1 之间。
D. 介于 -1 和 1 之间。
----------------------------------------------------------------

----------------------------------------------------------------
科目：machine_learning
54. 问题：下列哪项只能在训练数据线性可分时使用？ (machine_learning)
A. 线性硬边距 SVM。
B. 线性逻辑回归。
C. 线性软边距 SVM。
D. 质心法。
----------------------------------------------------------------

----------------------------------------------------------------
科目：machine_learning
55. 问题：下列哪些是空间聚类算法？ (machine_learning)
A. 基于分区的聚类
B. K 均值聚类
C. 基于网格的聚类
D. 以上所有
----------------------------------------------------------------

----------------------------------------------------------------
科目：machine_learning
56. 问题：陈述 1| 支持向量机构建的最大边距决策边界在所有线性分类器中具有最低的泛化误差。陈述 2| 我们从具有类条件高斯分布的生成模型中获得的任何决策边界原则上都可以用 SVM 和次数小于或等于三的多项式核来重现。 (machine_learning)
A. 正确，正确
B. 错误，错误
C. 正确，错误
D. 错误，正确
----------------------------------------------------------------

----------------------------------------------------------------
科目：machine_learning
57. 问题：陈述 1| 线性模型的 L2 正则化往往比 L1 正则化使模型更稀疏。陈述 2|残差连接可以在 ResNets 和 Transformers 中找到。 (machine_learning)
A. 正确，正确
B. 错误，错误
C. 正确，错误
D. 错误，正确
----------------------------------------------------------------

----------------------------------------------------------------
科目：machine_learning
58. 问题：假设我们想计算 P(H|E, F)，并且我们没有条件独立性信息。以下哪组数字足以进行计算？ (machine_learning)
A. P(E, F)、P(H)、P(E|H)、P(F|H)
B. P(E, F)、P(H)、P(E, F|H)
C. P(H)、P(E|H)、P(F|H)
D. P(E, F)、P(E|H)、P(F|H)
----------------------------------------------------------------

----------------------------------------------------------------
科目：machine_learning
59. 问题：以下哪项可以在进行装袋算法时防止过度拟合？ (machine_learning)
A. 使用替换抽样作为抽样技术
B. 使用弱分类器
C. 使用不易过度拟合的分类算法
D. 对每个经过训练的分类器进行验证的做法
----------------------------------------------------------------

----------------------------------------------------------------
科目：machine_learning
60. 问题：陈述 1| PCA 和谱聚类（例如 Andrew Ng 的）对两个不同的矩阵执行特征分解。但是，这两个矩阵的大小相同。陈述 2| 由于分类是回归的特殊情况，因此逻辑回归是线性回归的特殊情况。 (machine_learning)
A. 正确，正确
B. 错误，错误
C. 正确，错误
D. 错误，正确
----------------------------------------------------------------

----------------------------------------------------------------
科目：machine_learning
61. 问题：陈述 1| 斯坦福情绪树库包含电影评论，而不是书评。陈述 2| 宾夕法尼亚树库已用于语言建模。 (machine_learning)
A. 正确，正确
B. 错误，错误
C. 正确，错误
D. 错误，正确
----------------------------------------------------------------

----------------------------------------------------------------
科目：machine_learning
62. 问题：以下矩阵的零空间的维数是多少？A = [[3, 2, −9], [−6, −4, 18], [12, 8, −36]] (machine_learning)
A. 0
B. 1
C. 2
D. 3
----------------------------------------------------------------

----------------------------------------------------------------
科目：machine_learning
63. 问题：什么是支持向量？ (machine_learning)
A. 距离决策边界最远的示例。
B. 在 SVM 中计算 f(x) 所需的唯一示例。
C. 数据集心。
D. 所有在 SVM 中具有非零权重 αk 的示例。
----------------------------------------------------------------

----------------------------------------------------------------
科目：machine_learning
64. 问题：陈述 1| Word2Vec 参数未使用受限玻尔兹曼机初始化。陈述 2| tanh 函数是非线性激活函数。 (machine_learning)
A. 正确，正确
B. 错误，错误
C. 正确，错误
D. 错误，正确
----------------------------------------------------------------

----------------------------------------------------------------
科目：machine_learning
65. 问题：如果您的训练损失随着训练次数的增加而增加，则以下哪项可能是学习过程中存在的问题？ (machine_learning)
A. 正则化太低，模型过度拟合
B. 正则化太高，模型欠拟合
C. 步长太大
D. 步长太小
----------------------------------------------------------------

----------------------------------------------------------------
科目：machine_learning
66. 问题：假设疾病 D 的发病率约为每 100 人 5 例（即 P(D) = 0.05）。让布尔随机变量 D 表示患者“患有疾病 D”，让布尔随机变量 TP 代表“检测呈阳性”。众所周知，对疾病 D 的检测非常准确，因为当您患有疾病时检测结果为阳性的概率为 0.99，而当您没有患病时检测结果为阴性的概率为 0.97。当检测结果为阳性时，您患有疾病 D 的后验概率 P(D | TP) 是多少？ (machine_learning)
A. 0.0495
B. 0.078
C. 0.635
D. 0.97
----------------------------------------------------------------

----------------------------------------------------------------
科目：machine_learning
67. 问题：陈述 1| 传统的机器学习结果假设训练集和测试集是独立且同分布的。陈述 2| 2017 年，COCO 模型通常在 ImageNet 上进行预训练。 (machine_learning)
A. 正确，正确
B. 错误，错误
C. 正确，错误
D. 错误，正确
----------------------------------------------------------------

----------------------------------------------------------------
科目：machine_learning
68. 问题：陈述 1| 两个不同的内核 K1(x, x0) 和 K2(x, x0) 在同一个训练集上获得的边距值并不能告诉我们哪个分类器在测试集上的表现会更好。陈述 2| BERT 的激活函数是 GELU。 (machine_learning)
A. 正确，正确
B. 错误，错误
C. 正确，错误
D. 错误，正确
----------------------------------------------------------------

----------------------------------------------------------------
科目：machine_learning
69. 问题：以下哪项是机器学习中的聚类算法？ (machine_learning)
A. 期望最大化
B. CART
C. 高斯朴素贝叶斯
D. 先验
----------------------------------------------------------------

----------------------------------------------------------------
科目：machine_learning
70. 问题：您刚刚完成了垃圾邮件分类决策树的训练，并且它在训练集和测试集上的表现都异常糟糕。您知道您的实现没有错误，那么是什么导致了问题？ (machine_learning)
A. 您的决策树太浅了。
B. 您需要提高学习率。
C. 您过度拟合了。
D. 以上都不是。
----------------------------------------------------------------

----------------------------------------------------------------
科目：machine_learning
71. 问题：K 倍交叉验证是 (machine_learning)
A. K 中的线性
B. K 中的二次
C. K 中的三次
D. K 中的指数
----------------------------------------------------------------

----------------------------------------------------------------
科目：machine_learning
72. 问题：陈述 1| 工业级神经网络通常在 CPU 上训练，而不是 GPU。陈述 2| ResNet-50 模型有超过 10 亿个参数。 (machine_learning)
A. 正确，正确
B. 错误，错误
C. 正确，错误
D. 错误，正确
----------------------------------------------------------------

----------------------------------------------------------------
科目：machine_learning
73. 问题：给定两个布尔随机变量 A 和 B，其中 P(A) = 1/2、P(B) = 1/3 和 P(A | ¬B) = 1/4，P(A | B) 是多少？ (machine_learning)
A. 1/6
B. 1/4
C. 3/4
D. 1
----------------------------------------------------------------

----------------------------------------------------------------
科目：machine_learning
74. 问题：人工智能带来的生存风险最常与以下哪位教授有关？ (machine_learning)
A. Nando de Frietas
B. Yann LeCun
C. Stuart Russell
D. Jitendra Malik
----------------------------------------------------------------

----------------------------------------------------------------
科目：machine_learning
75. 问题：陈述 1| 最大化逻辑回归模型的似然会产生多个局部最优值。陈述 2| 如果数据分布已知，则没有分类器能比朴素贝叶斯分类器做得更好。 (machine_learning)
A. 正确，正确
B. 错误，错误
C. 正确，错误
D. 错误，正确
----------------------------------------------------------------

----------------------------------------------------------------
科目：machine_learning
76. 问题：对于核回归，以下哪一个结构假设对欠拟合和过拟合之间的权衡影响最大： (machine_learning)
A. 核函数是高斯函数、三角形函数还是箱形函数
B. 我们使用欧几里得度量、L1 度量还是 L∞ 度量
C. 核宽度
D. 核函数的最大高度
----------------------------------------------------------------

----------------------------------------------------------------
科目：machine_learning
77. 问题：陈述 1| SVM 学习算法保证找到关于其对象函数的全局最优假设。陈述 2| 通过径向基核函数映射到特征空间 Q 后，感知器可能能够实现比其原始空间更好的分类性能（尽管我们不能保证这一点）。 (machine_learning)
A. 正确，正确
B. 错误，错误
C. 正确，错误
D. 错误，正确
----------------------------------------------------------------

----------------------------------------------------------------
科目：machine_learning
78. 问题：对于高斯贝叶斯分类器，以下哪一个结构假设对欠拟合和过拟合之间的权衡影响最大： (machine_learning)
A. 我们是通过最大似然法还是梯度下降法来学习类中心
B. 我们假设全类协方差矩阵还是对角类协方差矩阵
C. 我们是否有相等的类先验或从数据中估计的先验。
D. 我们是否允许类具有不同的均值向量或强制它们共享相同的均值向量
----------------------------------------------------------------

----------------------------------------------------------------
科目：machine_learning
79. 问题：陈述 1| 当训练数据集较小时，过拟合的可能性更大。陈述 2| 当假设空间较小时，过拟合的可能性更大。 (machine_learning)
A. 正确，正确
B. 错误，错误
C. 正确，错误
D. 错误，正确
----------------------------------------------------------------

----------------------------------------------------------------
科目：machine_learning
80. 问题：陈述 1| 除了 EM，梯度下降还可用于对高斯混合模型进行推理或学习。陈述 2 |假设属性数量固定，基于高斯的贝叶斯最优分类器可以在与数据集中的记录数量成线性关系的时间内学习完成。 (machine_learning)
A. 正确，正确
B. 错误，错误
C. 正确，错误
D. 错误，正确
----------------------------------------------------------------

----------------------------------------------------------------
科目：machine_learning
81. 问题：陈述 1| 在贝叶斯网络中，连接树算法的推理结果与变量消除的推理结果相同。陈述 2| 如果两个随机变量 X 和 Y 在给定另一个随机变量 Z 的情况下条件独立，则在相应的贝叶斯网络中，X 和 Y 的节点在给定 Z 的情况下是 d 分离的。 (machine_learning)
A. 正确，正确
B. 错误，错误
C. 正确，错误
D. 错误，正确
----------------------------------------------------------------

----------------------------------------------------------------
科目：machine_learning
82. 问题：给定一个来自心脏病患者的大量医疗记录数据集，尝试了解这些患者是否可能存在不同的群集，我们可以针对这些群集制定单独的治疗方案。这是什么样的学习问题？ (machine_learning)
A. 监督学习
B. 无监督学习
C. (a) 和 (b) 都一样
D. (a) 和 (b) 都不是
----------------------------------------------------------------

----------------------------------------------------------------
科目：machine_learning
83. 问题：在 PCA 中，您会怎么做才能获得与 SVD 相同的投影？ (machine_learning)
A. 将数据转换为零均值
B. 将数据转换为零中值
C. 不可能
D. 以上都不是
----------------------------------------------------------------

----------------------------------------------------------------
科目：machine_learning
84. 问题：陈述 1| 1-最近邻分类器的训练误差为 0。陈述 2| 随着数据点的数量增长到无穷大，MAP 估计值接近所有可能先验的 MLE 估计值。换句话说，给定足够的数据，先验的选择无关紧要。 (machine_learning)
A. 正确，正确
B. 错误，错误
C. 正确，错误
D. 错误，正确
----------------------------------------------------------------

----------------------------------------------------------------
科目：machine_learning
85. 问题：当使用正则化进行最小二乘回归时（假设可以精确进行优化），增加正则化参数 λ 的值（测试误差）。 (machine_learning)
A. 永远不会减少训练误差。
B. 永远不会增加训练误差。
C. 永远不会减少测试误差。
D. 永远不会增加
----------------------------------------------------------------

----------------------------------------------------------------
科目：machine_learning
86. 问题：以下哪项最能描述判别方法试图建模的内容？（w 是模型中的参数） (machine_learning)
A. p(y|x, w)
B. p(y, x)
C. p(w|x, w)
D. 以上都不是
----------------------------------------------------------------

----------------------------------------------------------------
科目：machine_learning
87. 问题：陈述 1|卷积神经网络的 CIFAR-10 分类性能可以超过 95%。陈述 2| 神经网络的集成不会提高分类准确率，因为它们学习的表示具有高度相关性。 (machine_learning)
A. 正确，正确
B. 错误，错误
C. 正确，错误
D. 错误，正确
----------------------------------------------------------------

----------------------------------------------------------------
科目：machine_learning
88. 问题：贝叶斯学派和频率学派在以下哪一点上存在分歧？ (machine_learning)
A. 在概率回归中使用非高斯噪声模型。
B. 在回归中使用概率建模。
C. 在概率模型中使用参数的先验分布。
D. 在高斯判别分析中使用类先验。
----------------------------------------------------------------

----------------------------------------------------------------
科目：machine_learning
89. 问题：陈述 1| BLEU 指标使用精度，而 ROGUE 指标使用召回率。陈述 2| 隐马尔可夫模型经常用于对英陈述子进行建模。 (machine_learning)
A. 正确，正确
B. 错误，错误
C. 正确，错误
D. 错误，正确
----------------------------------------------------------------

----------------------------------------------------------------
科目：machine_learning
90. 问题：陈述 1| ImageNet 具有各种分辨率的图像。陈述 2| Caltech-101 拥有的图像比 ImageNet 多。 (machine_learning)
A. 正确，正确
B. 错误，错误
C. 正确，错误
D. 错误，正确
----------------------------------------------------------------

----------------------------------------------------------------
科目：machine_learning
91. 问题：以下哪项更适合进行特征选择？ (machine_learning)
A. Ridge
B. Lasso
C. (a) 和 (b) 都适用
D. (a) 和 (b) 都不适合
----------------------------------------------------------------

----------------------------------------------------------------
科目：machine_learning
92. 问题：假设您获得了一个 EM 算法，该算法可以找到具有潜在变量的模型的最大似然估计值。要求您修改算法，以便找到 MAP 估计值。您需要修改哪个或哪些步骤？ (machine_learning)
A. 期望
B. 最大化
C. 无需修改
D. 两者都需要修改
----------------------------------------------------------------

----------------------------------------------------------------
科目：machine_learning
93. 问题：对于高斯贝叶斯分类器，以下哪一个结构假设对欠拟合和过拟合之间的权衡影响最大： (machine_learning)
A. 我们是通过最大似然法还是梯度下降法来学习类中心
B. 我们假设全类协方差矩阵还是对角类协方差矩阵
C. 我们是否有相等的类先验或从数据估计的先验
D. 我们是否允许类具有不同的均值向量或强制它们共享相同的均值向量
----------------------------------------------------------------

----------------------------------------------------------------
科目：machine_learning
94. 问题：陈述 1| 对于具有联合分布 p(x, y) 的任何两个变量 x 和 y，我们始终有 H[x, y] ≥ H[x] + H[y]，其中 H 是熵函数。陈述 2| 对于某些有向图，道德化会减少图中存在的边数。 (machine_learning)
A. 正确，正确
B. 错误，错误
C. 正确，错误
D. 错误，正确
----------------------------------------------------------------

----------------------------------------------------------------
科目：machine_learning
95. 问题：以下哪项不是监督学习？ (machine_learning)
A. PCA
B. 决策树
C. 线性回归
D. 朴素贝叶斯
----------------------------------------------------------------

----------------------------------------------------------------
科目：machine_learning
96. 问题：陈述 1| 神经网络的收敛取决于学习率。陈述 2| Dropout 将随机选择的激活值乘以零。 (machine_learning)
A. 正确，正确
B. 错误，错误
C. 正确，错误
D. 错误，正确
----------------------------------------------------------------

----------------------------------------------------------------
科目：machine_learning
97. 问题：给定布尔随机变量 A、B 和 C，并且它们之间不存在独立性或条件独立性假设，下列哪一项等于 P(A, B, C)？ (machine_learning)
A. P(A | B) * P(B | C) * P(C | A)
B. P(C | A, B) * P(A) * P(B)
C. P(A, B | C) * P(C)
D. P(A | B, C) * P(B | A, C) * P(C | A, B)
----------------------------------------------------------------

----------------------------------------------------------------
科目：machine_learning
98. 问题：下列哪项任务可以使用聚类得到最佳解决。 (machine_learning)
A. 根据各种线索预测降雨量
B. 检测信用卡欺诈交易
C. 训练机器人解决迷宫问题
D. 以上所有
----------------------------------------------------------------

----------------------------------------------------------------
科目：machine_learning
99. 问题：在线性回归中应用正则化惩罚后，您发现 w 的一些系数被归零。可能使用了以下哪种惩罚？ (machine_learning)
A. L0 范数
B. L1 范数
C. L2 范数
D. (a) 或 (b)
----------------------------------------------------------------

----------------------------------------------------------------
科目：machine_learning
100. 问题：A 和 B 是两个事件。如果 P(A, B) 减少而 P(A) 增加，则下列哪项是正确的？ (machine_learning)
A. P(A|B) 减少
B. P(B|A) 减少
C. P(B) 减少
D. 以上全部
----------------------------------------------------------------

----------------------------------------------------------------
科目：machine_learning
101. 问题：陈述 1| 在为固定的一组观察值学习 HMM 时，假设我们不知道隐藏状态的真实数量（通常情况如此），我们总是可以通过允许更多隐藏状态来增加训练数据的可能性。陈述 2| 协同过滤通常是用于建模用户电影偏好的有用模型。 (machine_learning)
A. 正确，正确
B. 错误，错误
C. 正确，错误
D. 错误，正确
----------------------------------------------------------------

----------------------------------------------------------------
科目：machine_learning
102. 问题：您正在为一个简单的估计任务训练线性回归模型，并注意到该模型对数据过度拟合。您决定添加 $\ell_2$ 正则化来惩罚权重。随着 $\ell_2$ 正则化系数的增加，模型的偏差和方差会发生什么变化？ (machine_learning)
A. 偏差增加；方差增加
B. 偏差增加；方差减少
C. 偏差减少；方差增加
D. 偏差减少；方差减少
----------------------------------------------------------------

----------------------------------------------------------------
科目：machine_learning
103. 问题：哪些 PyTorch 1.8 命令生成 $10\times 5$ 高斯矩阵，其中每个条目 i.i.d. 均从 $\mathcal{N}(\mu=5,\sigma^2=16)$ 中采样，以及生成 $10\times 10$ 均匀矩阵，其中每个条目 i.i.d. 均从 $U[-1,1)$ 中采样？ (machine_learning)
A. \texttt{5 + torch.randn(10,5) * 16} ; \texttt{torch.rand(10,10,low=-1,high=1)}
B. \texttt{5 + torch.randn(10,5) * 16} ; \texttt{(torch.rand(10,10) - 0.5) / 0.5}
C. \texttt{5 + torch.randn(10,5) * 4} ; \texttt{2 * torch.rand(10,10) - 1}
D. \texttt{torch.normal(torch.ones(10,5)*5,torch.ones(5,5)*16)} ; \texttt{2 * torch.rand(10,10) - 1}
----------------------------------------------------------------

----------------------------------------------------------------
科目：machine_learning
104. 问题：陈述 1| 对于 $x<0$，ReLU 的梯度为零，对于所有 $x$，S 型梯度 $\sigma(x)(1-\sigma(x))\le \frac{1}{4}$。陈述 2| S 型梯度为连续梯度，而 ReLU 梯度为不连续梯度。 (machine_learning)
A. 正确，正确
B. 错误，错误
C. 正确，错误
D. 错误，正确
----------------------------------------------------------------

----------------------------------------------------------------
科目：machine_learning
105. 问题：关于批量标准化，哪项是正确的？ (machine_learning)
A. 应用批量标准化后，层的激活将遵循标准高斯分布。
B. 如果紧随其后的是批量标准化层，则仿射层的偏差参数将变得多余。
C. 使用批量标准化时，必须更改标准权重初始化。
D. 批量标准化相当于卷积神经网络的层标准化。
----------------------------------------------------------------

----------------------------------------------------------------
科目：machine_learning
106. 问题：假设我们有以下目标函数：$\argmin_{w} \frac{1}{2} \norm{Xw-y}^2_2 + \frac{1}{2}\gamma \norm{w}^2_2$$\frac{1}{2} \norm{Xw-y}^2_2 + \frac{1}{2}\lambda \norm{w}^2_2$ 相对于 $w$ 的梯度是多少？ (machine_learning)
A. $\nabla_w f(w) = (X^\top X + \lambda I)w - X^\top y + \lambda w$
B. $\nabla_w f(w) = X^\top X w - X^\top y + \lambda$
C. $\nabla_w f(w) = X^\top X w - X^\top y + \lambda w$
D. $\nabla_w f(w) = X^\top X w - X^\top y + (\lambda+1) w$
----------------------------------------------------------------

----------------------------------------------------------------
科目：machine_learning
107. 问题：下列哪项关于卷积核的说法是正确的？ (machine_learning)
A. 将图像与 $\begin{bmatrix}1 & 0 & 0\\ 0 & 1 & 0 \\ 0 & 0 & 1 \end{bmatrix}$ 进行卷积不会改变图像
B. 将图像与 $\begin{bmatrix}0 & 0 & 0\\ 0 & 1 & 0 \\ 0 & 0 & 0 \end{bmatrix}$ 进行卷积不会改变图像
C. 将图像与 $\begin{bmatrix}1 & 1 & 1\\ 1 & 1 & 1 \\ 1 & 1 & 1 \end{bmatrix}$ 进行卷积不会改变图像
D. 将图像与 $\begin{bmatrix}0 & 0 & 0\\ 0 & 0 & 0 \\ 0 & 0 & 0 \end{bmatrix}$ 进行卷积不会改变图像
----------------------------------------------------------------

----------------------------------------------------------------
科目：machine_learning
108. 问题：以下哪项是错误的？ (machine_learning)
A. 语义分割模型预测每个像素的类别，而多类图像分类器预测整个图像的类别。
B. IoU（交并比）等于 $96\%$ 的边界框可能被视为真阳性。
C. 当预测的边界框与场景中的任何对象都不对应时，它被视为假阳性。
D. IoU（交并比）等于 $3\%$ 的边界框可能被视为假阴性。
----------------------------------------------------------------

----------------------------------------------------------------
科目：machine_learning
109. 问题：以下哪项是错误的？ (machine_learning)
A. 以下没有激活函数的全连接网络是线性的：$g_3(g_2(g_1(x)))$，其中 $g_i(x) = W_i x$ 和 $W_i$ 是矩阵。
B. Leaky ReLU $\max\{0.01x,x\}$ 是凸的。
C. ReLU 的组合，例如 $ReLU(x) - ReLU(x-1)$ 是凸的。
D. 损失 $\log \sigma(x)= -\log(1+e^{-x})$ 是凹的。
----------------------------------------------------------------

----------------------------------------------------------------
科目：machine_learning
110. 问题：我们正在训练具有两个隐藏层的全连接网络来预测房价。输入是 $100$ 维的，并具有几个特征，例如平方英尺数、家庭收入中位数等。第一个隐藏层有 $1000$ 个激活。第二个隐藏层有 $10$ 个激活。输出是一个表示房价的标量。假设一个具有仿射变换的原始网络，没有批量归一化，激活函数中没有可学习的参数，这个网络有多少个参数？ (machine_learning)
A. 111021
B. 110010
C. 111110
D. 110011
----------------------------------------------------------------

----------------------------------------------------------------
科目：machine_learning
111. 问题：陈述 1| S 型函数 $\sigma(x)=(1+e^{-x})^{-1}$ 关于 $x$ 的导数等于 $\text{Var}(B)$，其中 $B\sim \text{Bern}(\sigma(x))$ 是伯努利随机变量。陈述 2| 将神经网络每一层的偏差参数设置为 0 会改变偏差-方差权衡，从而使模型的方差增加，模型的偏差减少 (machine_learning)
A. 正确，正确
B. 错误，错误
C. 正确，错误
D. 错误，正确
----------------------------------------------------------------

----------------------------------------------------------------
----------------------------------------